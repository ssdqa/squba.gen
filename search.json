[{"path":"https://ssdqa.github.io/squba.gen/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Hanieh Razzaghi. Author. Kaleigh Wieand. Author, maintainer. Kimberley Dickinson. Author. Charles Bailey. Author.","code":""},{"path":"https://ssdqa.github.io/squba.gen/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Razzaghi H, Wieand K, Dickinson K, Bailey C (2025). squba.gen: Study-Specific Quality, Utility, Breadth Assessment (SQUBA) Ecosystem Support Functions. R package version 0.0.0.9000, https://github.com/ssdqa/squba.gen.","code":"@Manual{,   title = {squba.gen: Study-Specific Quality, Utility, and Breadth Assessment (SQUBA) Ecosystem Support Functions},   author = {Hanieh Razzaghi and Kaleigh Wieand and Kimberley Dickinson and Charles Bailey},   year = {2025},   note = {R package version 0.0.0.9000},   url = {https://github.com/ssdqa/squba.gen}, }"},{"path":"https://ssdqa.github.io/squba.gen/index.html","id":"support-functions-for-the-squba-ecosystem","dir":"","previous_headings":"","what":"Study-Specific Quality, Utility, and Breadth Assessment (SQUBA) Ecosystem Support Functions","title":"Study-Specific Quality, Utility, and Breadth Assessment (SQUBA) Ecosystem Support Functions","text":"squba.gen package contains array support functions used modules throughout squba ecosystem. range color palettes used data visualizations anomaly detection methods drive many computations. functions intended used within squba modules applied results, can used contexts input data meets appropriate criteria.","code":""},{"path":"https://ssdqa.github.io/squba.gen/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Study-Specific Quality, Utility, and Breadth Assessment (SQUBA) Ecosystem Support Functions","text":"can install development version squba.gen like :","code":"devtools::install_github('ssdqa/squba.gen')"},{"path":"https://ssdqa.github.io/squba.gen/reference/anomalize_ss_anom_la.html","id":null,"dir":"Reference","previous_headings":"","what":"STL Regression Anomaly Detection — anomalize_ss_anom_la","title":"STL Regression Anomaly Detection — anomalize_ss_anom_la","text":"Single Site, Anomaly Detection, Longitudinal analyses time_period smaller year, function execute timetk::anomalize() identify outliers time series using STL regression. year-level analyses, input table returned different anomaly detection method used *_output stage","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/anomalize_ss_anom_la.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"STL Regression Anomaly Detection — anomalize_ss_anom_la","text":"","code":"anomalize_ss_anom_la(fot_input_tbl, grp_vars, time_var, var_col)"},{"path":"https://ssdqa.github.io/squba.gen/reference/anomalize_ss_anom_la.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"STL Regression Anomaly Detection — anomalize_ss_anom_la","text":"fot_input_tbl tabular input || required table, typically output compute_fot() grp_vars string vector || required variable(s) used grouping variables analysis. variables also preserved cross-join, meaning NAs artifact join variables. time_var string || required variable time period date information (typically time_start) var_col string || required variable numerical statistic interest euclidean distance computation","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/anomalize_ss_anom_la.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"STL Regression Anomaly Detection — anomalize_ss_anom_la","text":"yearly analyses, input table returned anomaly detection method executed via control chart *_output step. smaller time increments, function return input dataframe columns original input table plus columns needed timetk output generated anomalize function. include anomaly indicator variables related decomposition time series.","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/anomalize_ss_anom_la.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"STL Regression Anomaly Detection — anomalize_ss_anom_la","text":"","code":"# sample single-site, longitudinal input data (modeled after EVP) sample_ss_la_input <- dplyr::tibble('variable' = c('scd', 'scd', 'scd',                                                    'scd', 'scd', 'scd',                                                    'scd', 'scd', 'scd',                                                    'scd', 'scd', 'scd',                                                    'scd', 'scd'),                              'site' = c('Site A','Site A','Site A',                                         'Site A','Site A','Site A',                                         'Site A','Site A','Site A',                                         'Site A','Site A','Site A',                                         'Site A','Site A'),                              'count' = c(15, 24, 100, 93, 47, 65,                                          33, 92, 153, 122, 5, 99,                                          10, 30),                              'time_start'=c('2018-01-01', '2018-02-01',                                 '2018-03-01', '2018-04-01', '2018-05-01',                                 '2018-06-01', '2018-07-01', '2018-08-01',                                 '2018-09-01', '2018-10-01', '2018-11-01',                                 '2018-12-01', '2019-01-01', '2019-02-01'),                              'time_increment' = c('month','month','month',                                    'month', 'month','month', 'month','month',                                    'month','month','month','month','month',                                    'month')) # execute 'anomalization' from timetk package to find anomalies anomalize_ss_anom_la(fot_input_tbl = sample_ss_la_input %>%                          dplyr::mutate(time_start = as.Date(time_start)),                      grp_vars = c('site','variable'),                      time_var = 'time_start',                      var_col = 'count') #> Joining with `by = join_by(time_start, site, variable)` #> frequency = 3 observations per 1 quarter #> trend = 14 (Number of observations insufficient for shorter trend cycles. #> Joining with `by = join_by(time_start, site, variable)` #> # A tibble: 14 × 16 #>    time_start site   variable count time_increment observed season trend #>    <date>     <chr>  <chr>    <dbl> <chr>             <dbl>  <dbl> <dbl> #>  1 2018-01-01 Site A scd         15 month                15  -12.1  44.7 #>  2 2018-02-01 Site A scd         24 month                24  -24.7  50.3 #>  3 2018-03-01 Site A scd        100 month               100   36.8  55.9 #>  4 2018-04-01 Site A scd         93 month                93  -12.1  61.5 #>  5 2018-05-01 Site A scd         47 month                47  -24.7  67.1 #>  6 2018-06-01 Site A scd         65 month                65   36.8  72.0 #>  7 2018-07-01 Site A scd         33 month                33  -12.1  76.8 #>  8 2018-08-01 Site A scd         92 month                92  -24.7  74.0 #>  9 2018-09-01 Site A scd        153 month               153   36.8  71.2 #> 10 2018-10-01 Site A scd        122 month               122  -12.1  67.8 #> 11 2018-11-01 Site A scd          5 month                 5  -24.7  64.4 #> 12 2018-12-01 Site A scd         99 month                99   36.8  60.3 #> 13 2019-01-01 Site A scd         10 month                10  -12.1  56.2 #> 14 2019-02-01 Site A scd         30 month                30  -24.7  51.1 #> # ℹ 8 more variables: remainder <dbl>, seasadj <dbl>, anomaly <chr>, #> #   anomaly_direction <dbl>, anomaly_score <dbl>, recomposed_l1 <dbl>, #> #   recomposed_l2 <dbl>, observed_clean <dbl>"},{"path":"https://ssdqa.github.io/squba.gen/reference/build_birth_date.html","id":null,"dir":"Reference","previous_headings":"","what":"Build birth_date Column — build_birth_date","title":"Build birth_date Column — build_birth_date","text":"function, specific OMOP CDM implementation, create aggregate birth_date column using year_of_birth, month_of_birth, day_of_birth","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/build_birth_date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build birth_date Column — build_birth_date","text":"","code":"build_birth_date(cohort, person_tbl)"},{"path":"https://ssdqa.github.io/squba.gen/reference/build_birth_date.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build birth_date Column — build_birth_date","text":"cohort tabular input || required table cohort members, contains least person_id column person_tbl tabular input || required CDM person table another table contains least person_id, year_of_birth, month_of_birth, day_of_birth","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/build_birth_date.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build birth_date Column — build_birth_date","text":"function return table new birth_date column combination year, month, day birth. intended facilitate computations using date birth, like computing age.","code":""},{"path":[]},{"path":"https://ssdqa.github.io/squba.gen/reference/calc_days_between_dates.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Date Differences in Multiple SQL Backends — calc_days_between_dates","title":"Calculate Date Differences in Multiple SQL Backends — calc_days_between_dates","text":"Function get sql code number days date1 date2. Adapted sql dialects Postgres, MSSQL, Snowflake, Oracle, BigQuery, Presto, & Spark.","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/calc_days_between_dates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Date Differences in Multiple SQL Backends — calc_days_between_dates","text":"","code":"calc_days_between_dates(   date_col_1,   date_col_2,   db = get_argos_default()$config(\"db_src\") )"},{"path":"https://ssdqa.github.io/squba.gen/reference/calc_days_between_dates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Date Differences in Multiple SQL Backends — calc_days_between_dates","text":"date_col_1 Date col 1 date_col_2 Date col 2 db connection type object. Defaulted config('db_src') standard framework Functionality added Postgres, MS SQL Snowflake","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/calc_days_between_dates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Date Differences in Multiple SQL Backends — calc_days_between_dates","text":"integer representing difference (days) two provided dates","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/calc_days_between_dates.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Date Differences in Multiple SQL Backends — calc_days_between_dates","text":"always wrapped sql()","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/check_site_type.html","id":null,"dir":"Reference","previous_headings":"","what":"Check Site Type — check_site_type","title":"Check Site Type — check_site_type","text":"function evaluate number distinct values site column provided cohort table determine compares provided multi_or_single_site designation.","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/check_site_type.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check Site Type — check_site_type","text":"","code":"check_site_type(cohort, multi_or_single_site)"},{"path":"https://ssdqa.github.io/squba.gen/reference/check_site_type.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check Site Type — check_site_type","text":"cohort tabular input || required cohort used data quality testing. table contain, minimum: site | character | name(s) institutions included cohort person_id / patid | integer / character | patient identifier start_date | date | start cohort period end_date | date | end cohort period multi_or_single_site string || defaults single string, either single multi, indicating whether single-site multi-site analysis executed","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/check_site_type.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check Site Type — check_site_type","text":"multi_or_single_site = single multiple sites provided, cohort table returned summary site column set combined sites treated one group. Otherwise, existing site column returned -. illogical parameter combination supplied, function return error recommendations remedy issue.","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/check_site_type.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check Site Type — check_site_type","text":"","code":"## Create sample cohort cohort_sample <- dplyr::tibble(site = c('Site A', 'Site B', 'Site C'),                                person_id = c(1,2,3))  ## If number of sites & indicated multi/single site match, output same table check_site_type(cohort = cohort_sample,                 multi_or_single_site = 'multi') #> $cohort #> # A tibble: 3 × 2 #>   site   person_id #>   <chr>      <dbl> #> 1 Site A         1 #> 2 Site B         2 #> 3 Site C         3 #>  #> $grouped_list #> [1] \"site\" #>  #> $site_list_adj #> [1] \"Site A\" \"Site B\" \"Site C\" #>   ## If multiple sites but single site indicated, create site_summ column check_site_type(cohort = cohort_sample,                 multi_or_single_site = 'single') #> $cohort #> # A tibble: 3 × 3 #>   site   person_id site_summ #>   <chr>      <dbl> <chr>     #> 1 Site A         1 combined  #> 2 Site B         2 combined  #> 3 Site C         3 combined  #>  #> $grouped_list #> [1] \"site_summ\" #>  #> $site_list_adj #> [1] \"combined\" #>"},{"path":"https://ssdqa.github.io/squba.gen/reference/compute_age_groups_omop.html","id":null,"dir":"Reference","previous_headings":"","what":"Age at Cohort Entry – OMOP — compute_age_groups_omop","title":"Age at Cohort Entry – OMOP — compute_age_groups_omop","text":"Age Cohort Entry – OMOP","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/compute_age_groups_omop.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Age at Cohort Entry – OMOP — compute_age_groups_omop","text":"","code":"compute_age_groups_omop(cohort_tbl, person_tbl, age_groups)"},{"path":"https://ssdqa.github.io/squba.gen/reference/compute_age_groups_omop.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Age at Cohort Entry – OMOP — compute_age_groups_omop","text":"cohort_tbl table cohort members least person_id, start_date, end_date person_tbl CDM person table age_groups table user defines minimum maximum age allowed group provides string name group","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/compute_age_groups_omop.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Age at Cohort Entry – OMOP — compute_age_groups_omop","text":"cohort_tbl age cohort entry age group patient","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/compute_age_groups_pcnt.html","id":null,"dir":"Reference","previous_headings":"","what":"Age at Cohort Entry – PCORnet — compute_age_groups_pcnt","title":"Age at Cohort Entry – PCORnet — compute_age_groups_pcnt","text":"Age Cohort Entry – PCORnet","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/compute_age_groups_pcnt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Age at Cohort Entry – PCORnet — compute_age_groups_pcnt","text":"","code":"compute_age_groups_pcnt(cohort_tbl, person_tbl, age_groups)"},{"path":"https://ssdqa.github.io/squba.gen/reference/compute_age_groups_pcnt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Age at Cohort Entry – PCORnet — compute_age_groups_pcnt","text":"cohort_tbl table cohort members least person_id, start_date, end_date person_tbl CDM person table age_groups table user defines minimum maximum age allowed group provides string name group","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/compute_age_groups_pcnt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Age at Cohort Entry – PCORnet — compute_age_groups_pcnt","text":"cohort_tbl age cohort entry age group patient","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/compute_at_cross_join.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a cross-joined master table for variable reference — compute_at_cross_join","title":"Create a cross-joined master table for variable reference — compute_at_cross_join","text":"Create cross-joined master table variable reference","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/compute_at_cross_join.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a cross-joined master table for variable reference — compute_at_cross_join","text":"","code":"compute_at_cross_join(   cj_tbl,   cj_var_names = c(\"site\", \"concept_id\"),   join_type = \"left\" )"},{"path":"https://ssdqa.github.io/squba.gen/reference/compute_at_cross_join.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a cross-joined master table for variable reference — compute_at_cross_join","text":"cj_tbl table results longitudinal analysis cj_var_names vector names variables used \"anchor\" cross join combinations variables present final table join_type type join performed end function left used multi-site anomaly (euclidean distance) full used single site anomaly (timetk package)","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/compute_at_cross_join.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a cross-joined master table for variable reference — compute_at_cross_join","text":"one data frame combinations variables cj_var_names associated facts original cj_tbl input","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/compute_dist_anomalies.html","id":null,"dir":"Reference","previous_headings":"","what":"Hotspots Anomaly Detection Eligibility Determination — compute_dist_anomalies","title":"Hotspots Anomaly Detection Eligibility Determination — compute_dist_anomalies","text":"function , group dataframe, identify groups eligible anomaly detection analysis examining values var_col. following conditions disqualify group anomaly detection analysis: (1) Mean < 0.02 Median < 0.01 (2) Mean value < 0.05 range < 0.01 (3) Coefficient variance < 0.1 sample size < 11 groups meet criteria, warning display console indicating groups eligible.","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/compute_dist_anomalies.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hotspots Anomaly Detection Eligibility Determination — compute_dist_anomalies","text":"","code":"compute_dist_anomalies(df_tbl, grp_vars, var_col, denom_cols)"},{"path":"https://ssdqa.github.io/squba.gen/reference/compute_dist_anomalies.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hotspots Anomaly Detection Eligibility Determination — compute_dist_anomalies","text":"df_tbl tabular input || required dataframe least one numerical variable & relevant variables needed grouping grp_vars string vector || required variable(s) used grouping variables analysis var_col string || required variable numerical statistic interest euclidean distance computation denom_cols string vector || required variable containing denominator variables preserved without nulls cross_join takes place","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/compute_dist_anomalies.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hotspots Anomaly Detection Eligibility Determination — compute_dist_anomalies","text":"function return original df_tbl addition summary statistics used eligibility computation flag indicating whether given variable (based grp_vars) eligible anomaly detection analysis. table can passed detect_outliers identify anomalous values.","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/compute_dist_anomalies.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hotspots Anomaly Detection Eligibility Determination — compute_dist_anomalies","text":"","code":"# create sample input (modeled after EVP) sample_ms_input <- dplyr::tibble('site' = c('Site A', 'Site A', 'Site A',                                             'Site A', 'Site B', 'Site B',                                             'Site B', 'Site B'),                                  'variable' = c('dx', 'dx', 'drug', 'drug',                                                 'dx', 'dx', 'drug', 'drug'),                                  'count' = c(100, 140, 39, 42, 137, 111,                                              12, 15),                                  'total_var' = c(1000, 1000, 200, 200, 1500,                                                  1500, 100, 100)) # execute the full analysis, including compute_dist_anomalies and # detect_outliers anomaly_output1 <- compute_dist_anomalies(df_tbl = sample_ms_input,                                           grp_vars = 'variable',                                           var_col = 'count',                                           denom_cols = 'total_var') #> Joining with `by = join_by(site)` #> Joining with `by = join_by(site, variable, total_var)`  anomaly_output1 #> # A tibble: 12 × 14 #>    site   variable total_var count mean_val median_val sd_val mad_val cov_val #>    <chr>  <chr>        <dbl> <dbl>    <dbl>      <dbl>  <dbl>   <dbl>   <dbl> #>  1 Site A dx            1000   100     81.3      106.    64.8    48.9   0.797 #>  2 Site A dx            1000   140     81.3      106.    64.8    48.9   0.797 #>  3 Site A dx             200     0     81.3      106.    64.8    48.9   0.797 #>  4 Site A drug          1000     0     18         13.5   18.5    20.0   1.03  #>  5 Site A drug           200    39     18         13.5   18.5    20.0   1.03  #>  6 Site A drug           200    42     18         13.5   18.5    20.0   1.03  #>  7 Site B dx            1500   137     81.3      106.    64.8    48.9   0.797 #>  8 Site B dx            1500   111     81.3      106.    64.8    48.9   0.797 #>  9 Site B dx             100     0     81.3      106.    64.8    48.9   0.797 #> 10 Site B drug          1500     0     18         13.5   18.5    20.0   1.03  #> 11 Site B drug           100    12     18         13.5   18.5    20.0   1.03  #> 12 Site B drug           100    15     18         13.5   18.5    20.0   1.03  #> # ℹ 5 more variables: max_val <dbl>, min_val <dbl>, range_val <dbl>, #> #   total_ct <int>, analysis_eligible <chr>  anomaly_output2 <- detect_outliers(df_tbl = anomaly_output1,                                    column_analysis = 'count',                                    column_variable = 'variable') #> Joining with `by = join_by(site, variable, total_var, count, mean_val, #> median_val, sd_val, mad_val, cov_val, max_val, min_val, range_val, total_ct, #> analysis_eligible)`  anomaly_output2 #> # A tibble: 12 × 17 #>    site   variable total_var count mean_val median_val sd_val mad_val cov_val #>    <chr>  <chr>        <dbl> <dbl>    <dbl>      <dbl>  <dbl>   <dbl>   <dbl> #>  1 Site A dx            1000   100     81.3      106.    64.8    48.9   0.797 #>  2 Site A dx            1000   140     81.3      106.    64.8    48.9   0.797 #>  3 Site A dx             200     0     81.3      106.    64.8    48.9   0.797 #>  4 Site A drug          1000     0     18         13.5   18.5    20.0   1.03  #>  5 Site A drug           200    39     18         13.5   18.5    20.0   1.03  #>  6 Site A drug           200    42     18         13.5   18.5    20.0   1.03  #>  7 Site B dx            1500   137     81.3      106.    64.8    48.9   0.797 #>  8 Site B dx            1500   111     81.3      106.    64.8    48.9   0.797 #>  9 Site B dx             100     0     81.3      106.    64.8    48.9   0.797 #> 10 Site B drug          1500     0     18         13.5   18.5    20.0   1.03  #> 11 Site B drug           100    12     18         13.5   18.5    20.0   1.03  #> 12 Site B drug           100    15     18         13.5   18.5    20.0   1.03  #> # ℹ 8 more variables: max_val <dbl>, min_val <dbl>, range_val <dbl>, #> #   total_ct <int>, analysis_eligible <chr>, lower_tail <dbl>, #> #   upper_tail <dbl>, anomaly_yn <chr>"},{"path":"https://ssdqa.github.io/squba.gen/reference/compute_dist_mean_median.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Distance from Mean & Median — compute_dist_mean_median","title":"Compute Distance from Mean & Median — compute_dist_mean_median","text":"function , values given var_col, compute distance value mean & median values group established grp_vars parameter.","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/compute_dist_mean_median.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Distance from Mean & Median — compute_dist_mean_median","text":"","code":"compute_dist_mean_median(tbl, grp_vars, var_col, num_sd, num_mad)"},{"path":"https://ssdqa.github.io/squba.gen/reference/compute_dist_mean_median.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Distance from Mean & Median — compute_dist_mean_median","text":"tbl tabular input || required table target numerical variable (var_col) analysis required grouping variables (grp_vars) grp_vars string vector || required name variable(s) group computing summary statistics var_col string || required name numeric variable target summary statistic computations num_sd integer || required number standard deviations away mean used lower upper bounds outlier detection. Values falling, example, 2 standard deviations mean considered outliers. num_mad integer || required number median absolute deviations (MADs) away median used lower upper bounds. Outliers formally identified based median, information available final table prefer method.","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/compute_dist_mean_median.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Distance from Mean & Median — compute_dist_mean_median","text":"table , group grp_vars, various summary statistics like mean, median, standard deviation, MAD, others, computed based var_col. Outliers identified anomaly_yn column based whether data point +/- num_sd mean data point > 90th percentile.","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/compute_dist_mean_median.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Distance from Mean & Median — compute_dist_mean_median","text":"","code":"# sample input table sample_input <- dplyr::tibble('variable' = c('scd', 'scd', 'scd', 'scd'),                               'site' = c('Site A', 'Site A', 'Site B',                                          'Site B'),                               'count' = c(15, 24, 100, 93))  # execute function against sample data compute_dist_mean_median(tbl = sample_input,                          grp_vars = 'variable',                          var_col = 'count',                          num_sd = 1,                          num_mad = 1) #> Joining with `by = join_by(site, variable)` #> Joining with `by = join_by(variable)` #> # A tibble: 4 × 16 #>   site   variable count  mean median    sd   mad `90th_percentile` sd_lower #>   <chr>  <chr>    <dbl> <dbl>  <dbl> <dbl> <dbl>             <dbl>    <dbl> #> 1 Site A scd         15    58   58.5  44.7  56.3              99.0     13.3 #> 2 Site A scd         24    58   58.5  44.7  56.3              99.0     13.3 #> 3 Site B scd        100    58   58.5  44.7  56.3              99.0     13.3 #> 4 Site B scd         93    58   58.5  44.7  56.3              99.0     13.3 #> # ℹ 7 more variables: sd_upper <dbl>, mad_lower <dbl>, mad_upper <dbl>, #> #   anomaly_yn <lgl>, abs_diff_mean <dbl>, abs_diff_median <dbl>, n_mad <dbl>"},{"path":"https://ssdqa.github.io/squba.gen/reference/compute_euclidean.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Euclidean Distance — compute_euclidean","title":"Compute Euclidean Distance — compute_euclidean","text":"Compute Euclidean Distance","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/compute_euclidean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Euclidean Distance — compute_euclidean","text":"","code":"compute_euclidean(ms_tbl, output_var, grp_vars = c(\"site\", \"concept_id\"))"},{"path":"https://ssdqa.github.io/squba.gen/reference/compute_euclidean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Euclidean Distance — compute_euclidean","text":"ms_tbl output compute_dist_mean_median() cross-joined table compute_at_cross_join() used input output_var output variable used compute Euclidean distance .e. count proportion grp_vars vector grouping variables; euclidean distance computed per group","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/compute_euclidean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Euclidean Distance — compute_euclidean","text":"one dataframe variables ms_tbl addition columns site Loess value site Euclidean distance value","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/compute_fot.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Facts Over Time — compute_fot","title":"Compute Facts Over Time — compute_fot","text":"function loop time series execute user-provided function data within time period interest. also ensure patients whose start date passed whose end date passed included analysis given time period. means , example, patient cohort period 1/1/2020 1/1/2025 included looking year 2024, included looking year 2019 yet entered cohort.","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/compute_fot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Facts Over Time — compute_fot","text":"","code":"compute_fot(   cohort,   check_func,   site_col,   reduce_id = NULL,   time_period = \"year\",   time_span = c(\"2012-01-01\", \"2020-12-31\"),   site_list )"},{"path":"https://ssdqa.github.io/squba.gen/reference/compute_fot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Facts Over Time — compute_fot","text":"cohort tabular input || required cohort used data quality testing. table contain, minimum: site | character | name(s) institutions included cohort person_id / patid | integer / character | patient identifier start_date | date | start cohort period end_date | date | end cohort period Note start end dates included table used limit search window analyses module. check_func function || required function executed within time period loop. parameter structured following, dat input data function: function(dat){check_function(param1 = dat, param2 = param2_input, ..., paramX = paramX_input)} Make sure include parameters required original function default values used. site_col string || required name column cohort table contains site names. typically either site site_summ reduce_id string || defaults NULL function provided check_func returns list tables, parameter name column used reduce tables one dataframe (via dplyr::bind_rows) time_period string || defaults year string indicating distance dates within specified time_span. Defaults year, time periods month week also acceptable time_span vector - length 2 || defaults c('2012-01-01', '2020-01-01') vector indicating lower upper bounds time series longitudinal analyses site_list list || required list sites like examine clinical facts. Can one site (single-site) multiple (multi-site). Ensure sites listed exist provided cohort table.","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/compute_fot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Facts Over Time — compute_fot","text":"function return dataframe output provided check_func executed time_period provided time_span sites included site_list","code":""},{"path":[]},{"path":"https://ssdqa.github.io/squba.gen/reference/compute_jaccard.html","id":null,"dir":"Reference","previous_headings":"","what":"Jaccard Index Anomaly Detection — compute_jaccard","title":"Jaccard Index Anomaly Detection — compute_jaccard","text":"function compute Jaccard Similarity Index combination two variables occur within specific patient's record. function compatible OMOP PCORnet CDMs based user's selection.","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/compute_jaccard.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Jaccard Index Anomaly Detection — compute_jaccard","text":"","code":"compute_jaccard(jaccard_input_tbl, var_col, omop_or_pcornet)"},{"path":"https://ssdqa.github.io/squba.gen/reference/compute_jaccard.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Jaccard Index Anomaly Detection — compute_jaccard","text":"jaccard_input_tbl tabular input || required table contains least person_id/patid variable column, row represents unique instance variable occurred given patient Alternatively, can list unique person_id/patid variable combinations var_col string || required name column within jaccard_input_table contains variables compared similarity index omop_or_pcornet string || required string, either omop pcornet, indicating CDM format data","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/compute_jaccard.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Jaccard Index Anomaly Detection — compute_jaccard","text":"table pairs variables, labeled concept1 concept2, counts & proportions patients concept individually (concept1_ct, concept1_prop, concept2_ct, concept2_prop), count patients concepts (cocount), count patients EITHER concept (concept_count_union), jaccard_index statistic","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/compute_jaccard.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Jaccard Index Anomaly Detection — compute_jaccard","text":"","code":"# create sample input with person identifier and variable associations sample_input <- dplyr::tibble('person_id' = c(1,1,2,2,3,4,5,5),                               'variable' = c('dx', 'drug', 'drug', 'dx',                                              'drug', 'dx', 'dx', 'drug')) # compute jaccard index compute_jaccard(jaccard_input_tbl = sample_input,                 var_col = 'variable',                 omop_or_pcornet = 'omop') #> # A tibble: 1 × 9 #>   concept1 concept2 cocount concept1_ct concept2_ct concept_count_union #>   <chr>    <chr>      <int>       <int>       <int>               <int> #> 1 dx       drug           3           4           4                   5 #> # ℹ 3 more variables: jaccard_index <dbl>, concept1_prop <dbl>, #> #   concept2_prop <dbl>"},{"path":"https://ssdqa.github.io/squba.gen/reference/detect_outliers.html","id":null,"dir":"Reference","previous_headings":"","what":"Hotspots Anomaly Detection — detect_outliers","title":"Hotspots Anomaly Detection — detect_outliers","text":"function identify anomalies dataframe using hotspots::outliers() function. assumes: (1) time component; (2) Table column indicating whether particular group row eligible analysis; (3) numerical variable exists used anomaly detection analysis conditions met output compute_dist_anomalies(), typically input function","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/detect_outliers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hotspots Anomaly Detection — detect_outliers","text":"","code":"detect_outliers(   df_tbl,   tail_input = \"both\",   p_input = 0.9,   column_analysis,   column_variable,   column_eligible = \"analysis_eligible\" )"},{"path":"https://ssdqa.github.io/squba.gen/reference/detect_outliers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hotspots Anomaly Detection — detect_outliers","text":"df_tbl tabular input || required table meeting previously described criteria. input typically table output compute_dist_anomalies() tail_input string || defaults string indicating whether outliers identified positive values, negative values, . Acceptable inputs positive, negative, p_input numeric || defaults 0.9 p-value threshold used identify anomalies column_analysis string || required name numerical column target anomaly detection analysis column_variable string || required name column variable analysis column related (ex: concept_id Concept Set Distribution module) column_eligible string || defaults analysis_eligible name column indicates eligibility analysis","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/detect_outliers.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hotspots Anomaly Detection — detect_outliers","text":"","code":"# create sample input (modeled after EVP) sample_ms_input <- dplyr::tibble('site' = c('Site A', 'Site A', 'Site A',                                             'Site A', 'Site B', 'Site B',                                             'Site B', 'Site B'),                                  'variable' = c('dx', 'dx', 'drug', 'drug',                                                 'dx', 'dx', 'drug', 'drug'),                                  'count' = c(100, 140, 39, 42, 137, 111,                                              12, 15),                                  'total_var' = c(1000, 1000, 200, 200, 1500,                                                  1500, 100, 100)) # execute the full analysis, including compute_dist_anomalies and # detect_outliers anomaly_output1 <- compute_dist_anomalies(df_tbl = sample_ms_input,                                           grp_vars = 'variable',                                           var_col = 'count',                                           denom_cols = 'total_var') #> Joining with `by = join_by(site)` #> Joining with `by = join_by(site, variable, total_var)`  anomaly_output1 #> # A tibble: 12 × 14 #>    site   variable total_var count mean_val median_val sd_val mad_val cov_val #>    <chr>  <chr>        <dbl> <dbl>    <dbl>      <dbl>  <dbl>   <dbl>   <dbl> #>  1 Site A dx            1000   100     81.3      106.    64.8    48.9   0.797 #>  2 Site A dx            1000   140     81.3      106.    64.8    48.9   0.797 #>  3 Site A dx             200     0     81.3      106.    64.8    48.9   0.797 #>  4 Site A drug          1000     0     18         13.5   18.5    20.0   1.03  #>  5 Site A drug           200    39     18         13.5   18.5    20.0   1.03  #>  6 Site A drug           200    42     18         13.5   18.5    20.0   1.03  #>  7 Site B dx            1500   137     81.3      106.    64.8    48.9   0.797 #>  8 Site B dx            1500   111     81.3      106.    64.8    48.9   0.797 #>  9 Site B dx             100     0     81.3      106.    64.8    48.9   0.797 #> 10 Site B drug          1500     0     18         13.5   18.5    20.0   1.03  #> 11 Site B drug           100    12     18         13.5   18.5    20.0   1.03  #> 12 Site B drug           100    15     18         13.5   18.5    20.0   1.03  #> # ℹ 5 more variables: max_val <dbl>, min_val <dbl>, range_val <dbl>, #> #   total_ct <int>, analysis_eligible <chr>  anomaly_output2 <- detect_outliers(df_tbl = anomaly_output1,                                    column_analysis = 'count',                                    column_variable = 'variable') #> Joining with `by = join_by(site, variable, total_var, count, mean_val, #> median_val, sd_val, mad_val, cov_val, max_val, min_val, range_val, total_ct, #> analysis_eligible)`  anomaly_output2 #> # A tibble: 12 × 17 #>    site   variable total_var count mean_val median_val sd_val mad_val cov_val #>    <chr>  <chr>        <dbl> <dbl>    <dbl>      <dbl>  <dbl>   <dbl>   <dbl> #>  1 Site A dx            1000   100     81.3      106.    64.8    48.9   0.797 #>  2 Site A dx            1000   140     81.3      106.    64.8    48.9   0.797 #>  3 Site A dx             200     0     81.3      106.    64.8    48.9   0.797 #>  4 Site A drug          1000     0     18         13.5   18.5    20.0   1.03  #>  5 Site A drug           200    39     18         13.5   18.5    20.0   1.03  #>  6 Site A drug           200    42     18         13.5   18.5    20.0   1.03  #>  7 Site B dx            1500   137     81.3      106.    64.8    48.9   0.797 #>  8 Site B dx            1500   111     81.3      106.    64.8    48.9   0.797 #>  9 Site B dx             100     0     81.3      106.    64.8    48.9   0.797 #> 10 Site B drug          1500     0     18         13.5   18.5    20.0   1.03  #> 11 Site B drug           100    12     18         13.5   18.5    20.0   1.03  #> 12 Site B drug           100    15     18         13.5   18.5    20.0   1.03  #> # ℹ 8 more variables: max_val <dbl>, min_val <dbl>, range_val <dbl>, #> #   total_ct <int>, analysis_eligible <chr>, lower_tail <dbl>, #> #   upper_tail <dbl>, anomaly_yn <chr>"},{"path":"https://ssdqa.github.io/squba.gen/reference/extract_color.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to extract colors as hex codes — extract_color","title":"Function to extract colors as hex codes — extract_color","text":"Function extract colors hex codes","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/extract_color.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to extract colors as hex codes — extract_color","text":"","code":"extract_color(...)"},{"path":"https://ssdqa.github.io/squba.gen/reference/extract_color.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to extract colors as hex codes — extract_color","text":"... Character names squba_colors_standard","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/extract_color.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to extract colors as hex codes — extract_color","text":"name hex code/s specified color example useage: extract_color() (returns colors) extract_color(\"rust\") (just returns \"rust\")","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/generate_ref_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a summary concept reference table — generate_ref_table","title":"Create a summary concept reference table — generate_ref_table","text":"several SQUBA modules, function used create summary reference table displays detailed breakdown concept usage","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/generate_ref_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a summary concept reference table — generate_ref_table","text":"","code":"generate_ref_table(tbl, id_col, name_col, denom, time = FALSE)"},{"path":"https://ssdqa.github.io/squba.gen/reference/generate_ref_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a summary concept reference table — generate_ref_table","text":"tbl tabular input || required table, typically generated within *_output function, contains concepts interest displayed reference table id_col string || required name column concepts summarized reference table name_col string || required name column concept name associated concept id_col denom string || required name column denominator count (numerical value) associated id_col displayed reference table time boolean || defaults FALSE boolean indicating whether input data stratified time. time analyses, provided denom column summed across entire time period -time value displayed.","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/generate_ref_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a summary concept reference table — generate_ref_table","text":"gt reference table summary information concepts included provided table. typically included complement graphical output.","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/generate_ref_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a summary concept reference table — generate_ref_table","text":"","code":"# generate reference table for non-time dependent concept summary  input_tbl_notime <- dplyr::tibble('concept_id' = c(1, 2, 3, 4),                                   'concept_name' = c('test1', 'test2',                                                      'test3', 'test4'),                                   'ct_concept' = c(100, 200, 300, 400),                                   'site' = c('Site A', 'Site A', 'Site A',                                   'Site A'))  generate_ref_table(tbl = input_tbl_notime,                    id_col = 'concept_id',                    name_col = 'concept_name',                    denom = 'ct_concept',                    time = FALSE)          Concept Reference Table              {\"x\":{\"tag\":{\"name\":\"Reactable\",\"attribs\":{\"data\":{\"site\":[\"Site A\",\"Site A\",\"Site A\",\"Site A\"],\"concept_id\":[1,2,3,4],\"concept_name\":[\"test1\",\"test2\",\"test3\",\"test4\"],\"denom_col\":[100,200,300,400]},\"columns\":[{\"id\":\"site\",\"name\":\"site\",\"type\":\"character\",\"na\":\"NA\",\"minWidth\":125,\"style\":\"function(rowInfo, colInfo) {\\nconst rowIndex = rowInfo.index + 1\\nif (colInfo.id === 'site' & rowIndex === 1) {\\n  return { backgroundColor: '#FF4D6F', color: '#FFFFFF' }\\n}\\n\\nif (colInfo.id === 'site' & rowIndex === 2) {\\n  return { backgroundColor: '#FF4D6F', color: '#FFFFFF' }\\n}\\n\\nif (colInfo.id === 'site' & rowIndex === 3) {\\n  return { backgroundColor: '#FF4D6F', color: '#FFFFFF' }\\n}\\n\\nif (colInfo.id === 'site' & rowIndex === 4) {\\n  return { backgroundColor: '#FF4D6F', color: '#FFFFFF' }\\n}\\n\\n}\",\"html\":true,\"align\":\"left\"},{\"id\":\"concept_id\",\"name\":\"concept_id\",\"type\":\"numeric\",\"na\":\"NA\",\"minWidth\":125,\"style\":\"function(rowInfo, colInfo) {\\nconst rowIndex = rowInfo.index + 1\\nif (colInfo.id === 'site' & rowIndex === 1) {\\n  return { backgroundColor: '#FF4D6F', color: '#FFFFFF' }\\n}\\n\\nif (colInfo.id === 'site' & rowIndex === 2) {\\n  return { backgroundColor: '#FF4D6F', color: '#FFFFFF' }\\n}\\n\\nif (colInfo.id === 'site' & rowIndex === 3) {\\n  return { backgroundColor: '#FF4D6F', color: '#FFFFFF' }\\n}\\n\\nif (colInfo.id === 'site' & rowIndex === 4) {\\n  return { backgroundColor: '#FF4D6F', color: '#FFFFFF' }\\n}\\n\\n}\",\"html\":true,\"align\":\"right\"},{\"id\":\"concept_name\",\"name\":\"concept_name\",\"type\":\"character\",\"na\":\"NA\",\"minWidth\":125,\"style\":\"function(rowInfo, colInfo) {\\nconst rowIndex = rowInfo.index + 1\\nif (colInfo.id === 'site' & rowIndex === 1) {\\n  return { backgroundColor: '#FF4D6F', color: '#FFFFFF' }\\n}\\n\\nif (colInfo.id === 'site' & rowIndex === 2) {\\n  return { backgroundColor: '#FF4D6F', color: '#FFFFFF' }\\n}\\n\\nif (colInfo.id === 'site' & rowIndex === 3) {\\n  return { backgroundColor: '#FF4D6F', color: '#FFFFFF' }\\n}\\n\\nif (colInfo.id === 'site' & rowIndex === 4) {\\n  return { backgroundColor: '#FF4D6F', color: '#FFFFFF' }\\n}\\n\\n}\",\"html\":true,\"align\":\"left\"},{\"id\":\"denom_col\",\"name\":\"Total Count\",\"type\":\"numeric\",\"na\":\"NA\",\"minWidth\":125,\"style\":\"function(rowInfo, colInfo) {\\nconst rowIndex = rowInfo.index + 1\\nif (colInfo.id === 'site' & rowIndex === 1) {\\n  return { backgroundColor: '#FF4D6F', color: '#FFFFFF' }\\n}\\n\\nif (colInfo.id === 'site' & rowIndex === 2) {\\n  return { backgroundColor: '#FF4D6F', color: '#FFFFFF' }\\n}\\n\\nif (colInfo.id === 'site' & rowIndex === 3) {\\n  return { backgroundColor: '#FF4D6F', color: '#FFFFFF' }\\n}\\n\\nif (colInfo.id === 'site' & rowIndex === 4) {\\n  return { backgroundColor: '#FF4D6F', color: '#FFFFFF' }\\n}\\n\\n}\",\"cell\":[\"100\",\"200\",\"300\",\"400\"],\"html\":true,\"align\":\"right\"}],\"searchable\":true,\"defaultPageSize\":10,\"showPageSizeOptions\":false,\"pageSizeOptions\":[10,25,50,100],\"paginationType\":\"numbers\",\"showPagination\":true,\"showPageInfo\":true,\"minRows\":1,\"height\":\"auto\",\"theme\":{\"color\":\"#333333\",\"backgroundColor\":\"#FFFFFF\",\"stripedColor\":\"rgba(128,128,128,0.05)\",\"style\":{\"font-family\":\"system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif\",\"fontSize\":\"16px\"},\"tableStyle\":{\"borderTopStyle\":\"solid\",\"borderTopWidth\":\"2px\",\"borderTopColor\":\"#D3D3D3\"},\"headerStyle\":{\"fontWeight\":\"normal\",\"backgroundColor\":\"transparent\",\"borderBottomStyle\":\"solid\",\"borderBottomWidth\":\"2px\",\"borderBottomColor\":\"#D3D3D3\"},\"groupHeaderStyle\":{\"fontWeight\":\"normal\",\"backgroundColor\":\"transparent\",\"borderBottomStyle\":\"solid\",\"borderBottomWidth\":\"2px\",\"borderBottomColor\":\"#D3D3D3\"},\"cellStyle\":{\"fontWeight\":\"normal\"}},\"elementId\":\"xombwkkeul\",\"dataKey\":\"66e6f3e0b075909f7a0ff8278820cf2c\"},\"children\":[]},\"class\":\"reactR_markup\"},\"evals\":[\"tag.attribs.columns.0.style\",\"tag.attribs.columns.1.style\",\"tag.attribs.columns.2.style\",\"tag.attribs.columns.3.style\"],\"jsHooks\":[]} # generate reference table for time dependent concept summary  input_tbl_time <- dplyr::tibble('concept_id' = c(1, 2, 3, 4, 1, 2, 3, 4),                                 'time_start' = c('2012-01-01', '2012-01-01',                                                  '2012-01-01', '2012-01-01',                                                  '2013-01-01', '2013-01-01',                                                  '2013-01-01', '2013-01-01'),                                 'time_increment' = c('year','year','year',                                                      'year','year','year',                                                      'year','year'),                                 'concept_name' = c('test1', 'test2', 'test3',                                                    'test4', 'test1', 'test2',                                                    'test3', 'test4'),                                 'ct_concept' = c(100, 200, 300, 400, 200,                                                  300, 400, 500),                                 'site' = c('Site A', 'Site A', 'Site A',                                            'Site A', 'Site A', 'Site A',                                            'Site A', 'Site A'))  generate_ref_table(tbl = input_tbl_time,                    id_col = 'concept_id',                    name_col = 'concept_name',                    denom = 'ct_concept',                    time = TRUE)          Concept Reference Table              {\"x\":{\"tag\":{\"name\":\"Reactable\",\"attribs\":{\"data\":{\"site\":[\"Site A\",\"Site A\",\"Site A\",\"Site A\"],\"concept_id\":[1,2,3,4],\"concept_name\":[\"test1\",\"test2\",\"test3\",\"test4\"],\"denom_col\":[300,500,700,900]},\"columns\":[{\"id\":\"site\",\"name\":\"site\",\"type\":\"character\",\"na\":\"NA\",\"minWidth\":125,\"style\":\"function(rowInfo, colInfo) {\\nconst rowIndex = rowInfo.index + 1\\nif (colInfo.id === 'site' & rowIndex === 1) {\\n  return { backgroundColor: '#FF4D6F', color: '#FFFFFF' }\\n}\\n\\nif (colInfo.id === 'site' & rowIndex === 2) {\\n  return { backgroundColor: '#FF4D6F', color: '#FFFFFF' }\\n}\\n\\nif (colInfo.id === 'site' & rowIndex === 3) {\\n  return { backgroundColor: '#FF4D6F', color: '#FFFFFF' }\\n}\\n\\nif (colInfo.id === 'site' & rowIndex === 4) {\\n  return { backgroundColor: '#FF4D6F', color: '#FFFFFF' }\\n}\\n\\n}\",\"html\":true,\"align\":\"left\"},{\"id\":\"concept_id\",\"name\":\"concept_id\",\"type\":\"numeric\",\"na\":\"NA\",\"minWidth\":125,\"style\":\"function(rowInfo, colInfo) {\\nconst rowIndex = rowInfo.index + 1\\nif (colInfo.id === 'site' & rowIndex === 1) {\\n  return { backgroundColor: '#FF4D6F', color: '#FFFFFF' }\\n}\\n\\nif (colInfo.id === 'site' & rowIndex === 2) {\\n  return { backgroundColor: '#FF4D6F', color: '#FFFFFF' }\\n}\\n\\nif (colInfo.id === 'site' & rowIndex === 3) {\\n  return { backgroundColor: '#FF4D6F', color: '#FFFFFF' }\\n}\\n\\nif (colInfo.id === 'site' & rowIndex === 4) {\\n  return { backgroundColor: '#FF4D6F', color: '#FFFFFF' }\\n}\\n\\n}\",\"html\":true,\"align\":\"right\"},{\"id\":\"concept_name\",\"name\":\"concept_name\",\"type\":\"character\",\"na\":\"NA\",\"minWidth\":125,\"style\":\"function(rowInfo, colInfo) {\\nconst rowIndex = rowInfo.index + 1\\nif (colInfo.id === 'site' & rowIndex === 1) {\\n  return { backgroundColor: '#FF4D6F', color: '#FFFFFF' }\\n}\\n\\nif (colInfo.id === 'site' & rowIndex === 2) {\\n  return { backgroundColor: '#FF4D6F', color: '#FFFFFF' }\\n}\\n\\nif (colInfo.id === 'site' & rowIndex === 3) {\\n  return { backgroundColor: '#FF4D6F', color: '#FFFFFF' }\\n}\\n\\nif (colInfo.id === 'site' & rowIndex === 4) {\\n  return { backgroundColor: '#FF4D6F', color: '#FFFFFF' }\\n}\\n\\n}\",\"html\":true,\"align\":\"left\"},{\"id\":\"denom_col\",\"name\":\"Total Count (All Time Points)\",\"type\":\"numeric\",\"na\":\"NA\",\"minWidth\":125,\"style\":\"function(rowInfo, colInfo) {\\nconst rowIndex = rowInfo.index + 1\\nif (colInfo.id === 'site' & rowIndex === 1) {\\n  return { backgroundColor: '#FF4D6F', color: '#FFFFFF' }\\n}\\n\\nif (colInfo.id === 'site' & rowIndex === 2) {\\n  return { backgroundColor: '#FF4D6F', color: '#FFFFFF' }\\n}\\n\\nif (colInfo.id === 'site' & rowIndex === 3) {\\n  return { backgroundColor: '#FF4D6F', color: '#FFFFFF' }\\n}\\n\\nif (colInfo.id === 'site' & rowIndex === 4) {\\n  return { backgroundColor: '#FF4D6F', color: '#FFFFFF' }\\n}\\n\\n}\",\"cell\":[\"300\",\"500\",\"700\",\"900\"],\"html\":true,\"align\":\"right\"}],\"searchable\":true,\"defaultPageSize\":10,\"showPageSizeOptions\":false,\"pageSizeOptions\":[10,25,50,100],\"paginationType\":\"numbers\",\"showPagination\":true,\"showPageInfo\":true,\"minRows\":1,\"height\":\"auto\",\"theme\":{\"color\":\"#333333\",\"backgroundColor\":\"#FFFFFF\",\"stripedColor\":\"rgba(128,128,128,0.05)\",\"style\":{\"font-family\":\"system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif\",\"fontSize\":\"16px\"},\"tableStyle\":{\"borderTopStyle\":\"solid\",\"borderTopWidth\":\"2px\",\"borderTopColor\":\"#D3D3D3\"},\"headerStyle\":{\"fontWeight\":\"normal\",\"backgroundColor\":\"transparent\",\"borderBottomStyle\":\"solid\",\"borderBottomWidth\":\"2px\",\"borderBottomColor\":\"#D3D3D3\"},\"groupHeaderStyle\":{\"fontWeight\":\"normal\",\"backgroundColor\":\"transparent\",\"borderBottomStyle\":\"solid\",\"borderBottomWidth\":\"2px\",\"borderBottomColor\":\"#D3D3D3\"},\"cellStyle\":{\"fontWeight\":\"normal\"}},\"elementId\":\"bfdpbcyvkg\",\"dataKey\":\"5ab9510eda248171e34526cc29e6c585\"},\"children\":[]},\"class\":\"reactR_markup\"},\"evals\":[\"tag.attribs.columns.0.style\",\"tag.attribs.columns.1.style\",\"tag.attribs.columns.2.style\",\"tag.attribs.columns.3.style\"],\"jsHooks\":[]}"},{"path":"https://ssdqa.github.io/squba.gen/reference/initialize_dq_session.html","id":null,"dir":"Reference","previous_headings":"","what":"Initialize argos Session for squba Analysis — initialize_dq_session","title":"Initialize argos Session for squba Analysis — initialize_dq_session","text":"wrapper function create argos session set internal configurations allow downstream functions access argos convenience functions. step REQUIRED, makes easier connect backend database conduct analyses. standard argos workflow can also used, wrapper provided convenience.","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/initialize_dq_session.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initialize argos Session for squba Analysis — initialize_dq_session","text":"","code":"initialize_dq_session(   session_name,   db_conn,   is_json = FALSE,   working_directory = getwd(),   file_subdirectory,   results_subdirectory = NULL,   cdm_schema,   results_schema = NULL,   vocabulary_schema = NULL,   results_tag = NULL,   cache_enabled = FALSE,   retain_intermediates = FALSE,   db_trace = TRUE,   default_file_output = FALSE )"},{"path":"https://ssdqa.github.io/squba.gen/reference/initialize_dq_session.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initialize argos Session for squba Analysis — initialize_dq_session","text":"session_name string || required arbitrary name identify session db_conn string / database connection || required Either connection object used connect relational database (ex: output DBI::dbConnect()) string indicating path JSON file relevant connection information information used connect CDM access data indicated user analysis is_json boolean || defaults FALSE boolean indicating whether db_conn database connection object (FALSE) path JSON file connection details (TRUE) working_directory string || defaults result base::getwd() base directory analysis taking place expected file & results subdirectories directories downstream base directory. file_subdirectory string || required subdirectory within working_directory files used analysis (.e. concept sets) kept. name directory needs supplied , full file path including working_directory. parameter sets default file location squba functions can easily read relevant files without redefine path time. results_subdirectory string || defaults NULL subdirectory within base directory results output (file = TRUE using argos::output_tbl). name directory needs supplied , full file path including working_directory. cdm_schema string || required name schema data CDM format kept. location must exist within database identified db_conn results_schema string || defaults NULL name schema database results output (file = FALSE using argos::output_tbl). also location results can retrieved using argos::results_tbl vocabulary_schema string || defaults NULL name schema database vocabulary reference tables (like OMOP concept table) kept results_tag string || defaults NULL arbitrary suffix appended onto names result tables output using argos::output_tbl. feature can helpful re-running analysis want make sure tables uniquely identified. cache_enabled boolean || defaults FALSE boolean value indicating whether repeated attempts load codeset (via argos::load_codeset) use cached value rather reloading retain_intermediates boolean || defaults FALSE boolean indicating whether intermediate/temporary tables manifested retained database (defined results_schema) remain temporary objects db_trace boolean || defaults TRUE boolean indicating whether query log printed console include detailed information execution SQL queries database. essentially \"verbose\" parameter controlling much information want see certain queries executed. default_file_output boolean || defaults FALSE boolean indicating whether argos::output_tbl output file default just output results_schema database. can also controlled function level, option global setting like local, CSV copies results.","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/initialize_dq_session.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initialize argos Session for squba Analysis — initialize_dq_session","text":"function quietly load exported argos functions environment establish necessary configurations allow operate. Note argos session appear global environment.","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/initialize_dq_session.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Initialize argos Session for squba Analysis — initialize_dq_session","text":"","code":"if (FALSE) { # \\dontrun{  ## Create a database connection with DBI or input a file path ## to a json file with connection details conn_dbi <- DBI::dbConnect(drv = my_driver_func(), # insert appropriate driver                            dbname = \"my_dbname\",                            host = \"my_host\",                            port = \"my_port\",                            user = \"my_username\",                            password = \"my_password\")  conn_json <- \"path/to/connection/file\"  ## Establish session and load appropriate convenience functions & ## configurations into the environment  initialize_dq_session(session_name = \"my_session\",                       db_conn = conn_dbi,                       is_json = FALSE,                       working_directory = get_wd(),                       file_subdirectory = \"my_files\",                       cdm_schema = \"my_schema\")  } # }"},{"path":"https://ssdqa.github.io/squba.gen/reference/join_to_vocabulary.html","id":null,"dir":"Reference","previous_headings":"","what":"Join to a reference vocabulary table — join_to_vocabulary","title":"Join to a reference vocabulary table — join_to_vocabulary","text":"convenience function allows users join reference vocabulary table (likely OMOP concept table). intended pull full name concept facilitate review results.","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/join_to_vocabulary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Join to a reference vocabulary table — join_to_vocabulary","text":"","code":"join_to_vocabulary(tbl, vocab_tbl, col, vocab_col = \"concept_id\")"},{"path":"https://ssdqa.github.io/squba.gen/reference/join_to_vocabulary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Join to a reference vocabulary table — join_to_vocabulary","text":"tbl tabular input || required table vocabulary table joined vocab_tbl tabular input || required reference vocabulary table (ex: OMOP concept table). table minimally contain provided vocab_col, concept_name, vocabulary_id col string || required name column tbl used statement join vocab_col vocabulary table vocab_col string || defaults concept_id name column vocab_tbl used statement join col provided data table","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/join_to_vocabulary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Join to a reference vocabulary table — join_to_vocabulary","text":"function return dataframe provided tbl addition concept_name associated concept","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/join_to_vocabulary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Join to a reference vocabulary table — join_to_vocabulary","text":"","code":"if (FALSE) { # \\dontrun{  sample_input_tbl <- dplyr::tibble('concept' = c(1234, 5678, 91011),                                   'ct_concept' = c(100, 200, 300),                                   'site' = c('Site A', 'Site A', 'Site A'))  join_to_vocabulary(tbl = sample_input_tbl,                    vocab_tbl = vocabulary_tbl('concept'),                    col = 'concept',                    vocab_col = 'concept_id') } # }"},{"path":"https://ssdqa.github.io/squba.gen/reference/loop_through_visits.html","id":null,"dir":"Reference","previous_headings":"","what":"Patient Facts per Visit Type — loop_through_visits","title":"Patient Facts per Visit Type — loop_through_visits","text":"function loop site visit type provided execute provided check function compute facts stratified visit type. Primarily intended use Patient Facts module, can adapted use elsewhere.","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/loop_through_visits.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Patient Facts per Visit Type — loop_through_visits","text":"","code":"loop_through_visits(   cohort_tbl,   omop_or_pcornet,   check_func,   site_col,   time = FALSE,   visit_type_tbl,   visit_tbl,   site_list,   visit_list = c(\"outpatient\", \"inpatient\"),   domain_tbl )"},{"path":"https://ssdqa.github.io/squba.gen/reference/loop_through_visits.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Patient Facts per Visit Type — loop_through_visits","text":"cohort_tbl tabular input || required cohort used data quality testing. table contain, minimum: site | character | name(s) institutions included cohort person_id / patid | integer / character | patient identifier start_date | date | start cohort period end_date | date | end cohort period Note start end dates included table used limit search window analyses module. recommended table passed prepare_cohort function well. omop_or_pcornet string || required string, either omop pcornet, indicating CDM format data omop: run loop_through_visits_omop() function OMOP CDM instance pcornet: run loop_through_visits_pcnt() function PCORnet CDM instance check_func function || required function executed within time period loop. parameter structured following, cht cohort table t input data function: function(cht, t){check_function(param1 = cht, param2 = t, param3 = param3_input, ..., paramX = paramX_input)} Make sure include parameters required original function default values used. site_col string || required name column cohort table contains site names. typically either site site_summ time boolean || defaults FALSE boolean indicate whether execute longitudinal analysis visit_type_tbl tabular input || required table defines visit types interest called visit_list. input contain: visit_concept_id / visit_detail_concept_id enc_type | integer character | visit_(detail)_concept_id enc_type represents visit type interest (.e. 9201 IP) visit_type | character | string label describe visit type visit_tbl tabular input || defaults cdm_tbl('visit_occurrence') CDM table visit information (.e. visit_occurrence encounter) site_list list || required list sites like examine clinical facts. Can one site (single-site) multiple (multi-site). Ensure sites listed exist provided cohort table. visit_list string vector || defaults c('outpatient', 'inpatient') string vector visit types output stratified. visit type listed parameter match associated visit type defined visit_type_tbl domain_tbl tabular input || required table defines fact domains investigated analysis. input contain: domain | character | string label domain examined (.e. prescription drugs) domain_tbl | character | CDM table information domain can found (.e. drug_exposure) filter_logic | character | logic applied domain_tbl order achieve definition interest; written applying dplyr::filter command R","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/loop_through_visits.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Patient Facts per Visit Type — loop_through_visits","text":"function return list dataframes median number facts per patient domains domain_tbl, dataframe specific given visit type visit_list","code":""},{"path":[]},{"path":"https://ssdqa.github.io/squba.gen/reference/loop_through_visits_omop.html","id":null,"dir":"Reference","previous_headings":"","what":"Patient Facts per Visit Type – OMOP — loop_through_visits_omop","title":"Patient Facts per Visit Type – OMOP — loop_through_visits_omop","text":"Patient Facts per Visit Type – OMOP","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/loop_through_visits_omop.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Patient Facts per Visit Type – OMOP — loop_through_visits_omop","text":"","code":"loop_through_visits_omop(   cohort_tbl,   check_func,   site_col,   time = FALSE,   visit_type_tbl,   visit_tbl = cdm_tbl(\"visit_occurrence\"),   site_list,   visit_list = c(\"inpatient\", \"outpatient\"),   domain_tbl )"},{"path":"https://ssdqa.github.io/squba.gen/reference/loop_through_visits_omop.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Patient Facts per Visit Type – OMOP — loop_through_visits_omop","text":"cohort_tbl table members cohort run prepare_cohort() check_func base function check needs executed across time; argument structured following, cht cohort t input data function:   site_col column data site variable can found time logical indicating whether analysis conducted longitudinally visit_type_tbl table defines available visit types called visit_types.: visit_concept_id / visit_detail_concept_id: visit_(detail)_concept_id represents visit type interest (.e. 9201 IP) visit_type: string label describe visit type; label can used multiple times within file multiple visit_concept_ids/enc_types represent visit type visit_tbl cdm visit_occurrence visit_detail tbl site_list sites iterate visit_list list visit types iterate domain_tbl table defines domains facts identified following columns: domain: string label domain examined (.e. prescription drugs) domain_tbl: CDM table information domain can found (.e. drug_exposure) filter_logic: optional string parsed logic filter domain_tbl needed best represent domain","code":"function(cht, t){check_function(param1 = cht, param2 = t, param3 = param3_input, ...,               paramX = paramX_input)}                all parameters for the base check function should be included if any defaults are not being               used"},{"path":"https://ssdqa.github.io/squba.gen/reference/loop_through_visits_omop.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Patient Facts per Visit Type – OMOP — loop_through_visits_omop","text":"list dataframes median number facts per patient domains domain_tbl, dataframe specific given visit type visit_list","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/loop_through_visits_pcnt.html","id":null,"dir":"Reference","previous_headings":"","what":"Patient Facts per Visit Type – PCORnet — loop_through_visits_pcnt","title":"Patient Facts per Visit Type – PCORnet — loop_through_visits_pcnt","text":"Patient Facts per Visit Type – PCORnet","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/loop_through_visits_pcnt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Patient Facts per Visit Type – PCORnet — loop_through_visits_pcnt","text":"","code":"loop_through_visits_pcnt(   cohort_tbl,   check_func,   site_col,   time = FALSE,   visit_type_tbl,   visit_tbl = cdm_tbl(\"encounter\"),   site_list,   visit_list = c(\"inpatient\", \"outpatient\"),   domain_tbl )"},{"path":"https://ssdqa.github.io/squba.gen/reference/loop_through_visits_pcnt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Patient Facts per Visit Type – PCORnet — loop_through_visits_pcnt","text":"cohort_tbl table members cohort run prepare_cohort() check_func base function check needs executed across time; argument structured following, cht cohort t input data function:   site_col column data site variable can found time logical indicating whether analysis conducted longitudinally visit_type_tbl table defines available visit types called visit_list. enc_type: enc_type represents visit type interest (.e. 9201 IP) visit_type: string label describe visit type; label can used multiple times within file multiple visit_concept_ids/enc_types represent visit type visit_tbl cdm encounter tbl site_list sites iterate visit_list list visit types iterate domain_tbl table defines domains facts identified following columns: domain: string label domain examined (.e. prescription drugs) domain_tbl: CDM table information domain can found (.e. drug_exposure) filter_logic: optional string parsed logic filter domain_tbl needed best represent domain","code":"function(cht, t){check_function(param1 = cht, param2 = t, param3 = param3_input, ...,               paramX = paramX_input)}                all parameters for the base check function should be included if any defaults are not being               used"},{"path":"https://ssdqa.github.io/squba.gen/reference/loop_through_visits_pcnt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Patient Facts per Visit Type – PCORnet — loop_through_visits_pcnt","text":"list dataframes median number facts per patient domains domain_tbl, dataframe specific given visit type visit_list","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/make_interactive_squba.html","id":null,"dir":"Reference","previous_headings":"","what":"Make squba outputs interactive — make_interactive_squba","title":"Make squba outputs interactive — make_interactive_squba","text":"function converts ggplot object output *_output functions interactive ggiraph plotly object.","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/make_interactive_squba.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make squba outputs interactive — make_interactive_squba","text":"","code":"make_interactive_squba(ggplot_obj)"},{"path":"https://ssdqa.github.io/squba.gen/reference/make_interactive_squba.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make squba outputs interactive — make_interactive_squba","text":"ggplot_obj ggplot || required ggplot object output *_output functions native module. work graphs generated squba, adds additional metadata plot required function work.","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/make_interactive_squba.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make squba outputs interactive — make_interactive_squba","text":"graph interactive functionality pre-set tooltips based either ggiraph package plotly package","code":""},{"path":[]},{"path":"https://ssdqa.github.io/squba.gen/reference/ms_anom_euclidean.html","id":null,"dir":"Reference","previous_headings":"","what":"Euclidean Distance Computation — ms_anom_euclidean","title":"Euclidean Distance Computation — ms_anom_euclidean","text":"function compute Euclidean Distance var_col site comparison overall, -site mean. backend Multi Site, Anomaly Detection, Longitudinal analyses.","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/ms_anom_euclidean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Euclidean Distance Computation — ms_anom_euclidean","text":"","code":"ms_anom_euclidean(fot_input_tbl, grp_vars, var_col)"},{"path":"https://ssdqa.github.io/squba.gen/reference/ms_anom_euclidean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Euclidean Distance Computation — ms_anom_euclidean","text":"fot_input_tbl tabular input || required table, typically output compute_fot() grp_vars string vector || required variable(s) used grouping variables analysis. variables also preserved cross-join, meaning NAs artifact join variables. var_col string || required variable numerical statistic interest euclidean distance computation","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/ms_anom_euclidean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Euclidean Distance Computation — ms_anom_euclidean","text":"function return original data frame, time periods without data filled 0s, mean median values var_col euclidean distance value based -site mean","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/ms_anom_euclidean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Euclidean Distance Computation — ms_anom_euclidean","text":"","code":"# sample multi-site, longitudinal input data (modeled after EVP) sample_ms_la_input <- dplyr::tibble('variable' = c('scd', 'scd', 'scd',                                                    'scd', 'scd', 'scd',                                                    'scd', 'scd', 'scd',                                                    'scd', 'scd', 'scd',                                                    'scd', 'scd'),                              'site' = c('Site A','Site A','Site A',                                         'Site A','Site A','Site A',                                         'Site A','Site B','Site B',                                         'Site B','Site B','Site B',                                         'Site B','Site B'),                              'count' = c(15, 24, 100, 93, 47, 65,                                          33, 92, 153, 122, 5, 99,                                          10, 30),                              'time_start'=c('2018-01-01','2019-01-01',                                    '2020-01-01', '2021-01-01', '2022-01-01',                                    '2023-01-01', '2024-01-01','2018-01-01',                                    '2019-01-01', '2020-01-01', '2021-01-01',                                    '2022-01-01', '2023-01-01', '2024-01-01'),                              'time_increment' = c('year','year','year',                                    'year', 'year','year', 'year','year',                                    'year','year','year','year','year',                                    'year'))  # compute euclidean distance for each site & variable combination ms_anom_euclidean(fot_input_tbl = sample_ms_la_input %>%                         dplyr::mutate(time_start = as.Date(time_start)),                   grp_vars = c('site', 'variable'),                   var_col = 'count') #> Joining with `by = join_by(time_start, site, variable)` #> Joining with `by = join_by(site, variable, time_start)` #> Joining with `by = join_by(variable, time_start)` #> # A tibble: 14 × 9 #>    site   time_start variable count mean_allsiteprop median date_numeric #>    <chr>  <date>     <chr>    <dbl>            <dbl>  <dbl>        <dbl> #>  1 Site A 2018-01-01 scd         15             53.5   53.5        17532 #>  2 Site A 2019-01-01 scd         24             88.5   88.5        17897 #>  3 Site A 2020-01-01 scd        100            111    111          18262 #>  4 Site A 2021-01-01 scd         93             49     49          18628 #>  5 Site A 2022-01-01 scd         47             73     73          18993 #>  6 Site A 2023-01-01 scd         65             37.5   37.5        19358 #>  7 Site A 2024-01-01 scd         33             31.5   31.5        19723 #>  8 Site B 2018-01-01 scd         92             53.5   53.5        17532 #>  9 Site B 2019-01-01 scd        153             88.5   88.5        17897 #> 10 Site B 2020-01-01 scd        122            111    111          18262 #> 11 Site B 2021-01-01 scd          5             49     49          18628 #> 12 Site B 2022-01-01 scd         99             73     73          18993 #> 13 Site B 2023-01-01 scd         10             37.5   37.5        19358 #> 14 Site B 2024-01-01 scd         30             31.5   31.5        19723 #> # ℹ 2 more variables: site_loess <dbl>, dist_eucl_mean <dbl>"},{"path":"https://ssdqa.github.io/squba.gen/reference/param_summ.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate output_function identifier & build output instructions — param_summ","title":"Generate output_function identifier & build output instructions — param_summ","text":"function summarize input parameters *_process functions, used output string console indicates appropriate output_function use *_output step","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/param_summ.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate output_function identifier & build output instructions — param_summ","text":"","code":"param_summ(check_string, ...)"},{"path":"https://ssdqa.github.io/squba.gen/reference/param_summ.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate output_function identifier & build output instructions — param_summ","text":"check_string string || required string abbreviation represent module (ex: evp, pf). prefixed names output functions ... parameters input primary *_process function. argument able vectorized (.e. CDM tbl, codeset, etc) appear final summary","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/param_summ.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate output_function identifier & build output instructions — param_summ","text":"string name output_function added final result table, avector information parameters required use *_output function module. vector intended fed cli message command generate console message.","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/param_summ.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate output_function identifier & build output instructions — param_summ","text":"","code":"# intended for use inside the *_process functions  param_summ(check_string = 'evp',            multi_or_single_site = 'single',            anomaly_or_exploratory = 'exploratory',            time = FALSE) #> Rows: 77 Columns: 5 #> ── Column specification ──────────────────────────────────────────────────────── #> Delimiter: \",\" #> chr (5): module, check, Always Required, Required for Check, Optional #>  #> ℹ Use `spec()` to retrieve the full column specification for this data. #> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. #> $vector #> [1] \"\\033[1m\\033[34mAlways Required\\033[39m\\033[22m: process_output\"  #> [2] \"\\033[1m\\033[34mRequired for Check\\033[39m\\033[22m: output_level\" #>  #> $string #> [1] \"evp_ss_exp_cs\" #>"},{"path":"https://ssdqa.github.io/squba.gen/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://ssdqa.github.io/squba.gen/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/prepare_cohort.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare Cohort — prepare_cohort","title":"Prepare Cohort — prepare_cohort","text":"cohort table input *_process functions, function prepare cohort rest analysis. includes computing follow-based start end dates computing age cohort entry categorized user-provided groups.","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/prepare_cohort.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare Cohort — prepare_cohort","text":"","code":"prepare_cohort(cohort_tbl, age_groups = NULL, omop_or_pcornet)"},{"path":"https://ssdqa.github.io/squba.gen/reference/prepare_cohort.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare Cohort — prepare_cohort","text":"cohort_tbl tabular input || required cohort used data quality testing. table contain, minimum: site | character | name(s) institutions included cohort person_id / patid | integer / character | patient identifier start_date | date | start cohort period end_date | date | end cohort period age_groups tabular input || defaults NULL like stratify results age group, create table CSV file following columns use input parameter: min_age | integer | minimum age group (.e. 10) max_age | integer | maximum age group (.e. 20) group | character | string label group (.e. 10-20, Young Adult, etc.) like stratify age group, leave NULL omop_or_pcornet string || required string, either omop pcornet, indicating CDM format data","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/prepare_cohort.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare Cohort — prepare_cohort","text":"function return input cohort table addition column fu, includes length patient follow-based provided start & end dates. Optionally, age_groups NULL, output also include age_ce (patient age cohort entry) age_grp (user-provided age group category)","code":""},{"path":[]},{"path":"https://ssdqa.github.io/squba.gen/reference/replace_site_col.html","id":null,"dir":"Reference","previous_headings":"","what":"Replace Summary Site Column — replace_site_col","title":"Replace Summary Site Column — replace_site_col","text":"analyses summary site column created check_site_type(), function replace name column original \"site\" name.","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/replace_site_col.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Replace Summary Site Column — replace_site_col","text":"","code":"replace_site_col(tbl)"},{"path":"https://ssdqa.github.io/squba.gen/reference/replace_site_col.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Replace Summary Site Column — replace_site_col","text":"tbl tabular input || required table site_summ column needs replaced","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/replace_site_col.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Replace Summary Site Column — replace_site_col","text":"table used input, site replacing site_summ","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/replace_site_col.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Replace Summary Site Column — replace_site_col","text":"","code":"## Sample input table input_sample <- dplyr::tibble(person_id = c(1,2,3),                               site_summ = c(\"combined\",\"combined\",\"combined\"))  ## Replace site_summ col for final output replace_site_col(tbl = input_sample)"},{"path":"https://ssdqa.github.io/squba.gen/reference/scale_color_squba.html","id":null,"dir":"Reference","previous_headings":"","what":"squba Color Scale Constructor — scale_color_squba","title":"squba Color Scale Constructor — scale_color_squba","text":"function operate ggplot objects use squba standard colors/color palettes add color graphs","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/scale_color_squba.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"squba Color Scale Constructor — scale_color_squba","text":"","code":"scale_color_squba(palette = \"main\", discrete = TRUE, reverse = FALSE, ...)"},{"path":"https://ssdqa.github.io/squba.gen/reference/scale_color_squba.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"squba Color Scale Constructor — scale_color_squba","text":"palette string || defaults main name palette appears squba_palettes_standard discrete boolean || defaults TRUE boolean indicating whether color aesthetic discrete reverse boolean || defaults FALSE boolean indicating whether palette reversed ... additional arguments passed ggplot2::discrete_scale ggplot2::scale_color_gradientn, used respectively discrete TRUE FALSE","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/scale_color_squba.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"squba Color Scale Constructor — scale_color_squba","text":"","code":"library(ggplot2)  mtcars %>%   tibble::rownames_to_column('car_model') %>%   ggplot(aes(x = mpg, y = wt, color = car_model)) +   geom_point() +   scale_color_squba()"},{"path":"https://ssdqa.github.io/squba.gen/reference/scale_fill_squba.html","id":null,"dir":"Reference","previous_headings":"","what":"squba Fill Scale Constructor — scale_fill_squba","title":"squba Fill Scale Constructor — scale_fill_squba","text":"function operate ggplot objects use squba standard colors/color palettes add fill graphs","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/scale_fill_squba.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"squba Fill Scale Constructor — scale_fill_squba","text":"","code":"scale_fill_squba(palette = \"main\", discrete = TRUE, reverse = FALSE, ...)"},{"path":"https://ssdqa.github.io/squba.gen/reference/scale_fill_squba.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"squba Fill Scale Constructor — scale_fill_squba","text":"palette string || defaults main name palette appears squba_palettes_standard discrete boolean || defaults TRUE boolean indicating whether fill aesthetic discrete reverse boolean || defaults FALSE boolean indicating whether palette reversed ... additional arguments passed ggplot2::discrete_scale ggplot2::scale_fill_gradientn, used respectively discrete TRUE FALSE","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/scale_fill_squba.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"squba Fill Scale Constructor — scale_fill_squba","text":"","code":"library(ggplot2)  mtcars %>%   tibble::rownames_to_column('car_model') %>%   ggplot(aes(x = car_model, y = wt, fill = car_model)) +   geom_col() +   scale_fill_squba()"},{"path":"https://ssdqa.github.io/squba.gen/reference/squba_colors_standard.html","id":null,"dir":"Reference","previous_headings":"","what":"SQUBA Standard Color Hexes — squba_colors_standard","title":"SQUBA Standard Color Hexes — squba_colors_standard","text":"SQUBA Standard Color Hexes","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/squba_colors_standard.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"SQUBA Standard Color Hexes — squba_colors_standard","text":"","code":"squba_colors_standard"},{"path":"https://ssdqa.github.io/squba.gen/reference/squba_colors_standard.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"SQUBA Standard Color Hexes — squba_colors_standard","text":"object class character length 13.","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/squba_pal.html","id":null,"dir":"Reference","previous_headings":"","what":"Return function to interpolate a color palette — squba_pal","title":"Return function to interpolate a color palette — squba_pal","text":"Return function interpolate color palette","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/squba_pal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return function to interpolate a color palette — squba_pal","text":"","code":"squba_pal(palette, reverse = FALSE, ...)"},{"path":"https://ssdqa.github.io/squba.gen/reference/squba_pal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return function to interpolate a color palette — squba_pal","text":"palette Character name palette squba_palettes_standard reverse Boolean indicating whether palette reversed ... Additional arguments pass colorRampPalette()","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/squba_pal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return function to interpolate a color palette — squba_pal","text":"color palettes, interpolated necessary, specified scheme number colors example usage: squba_pal(\"beachy\")(10)","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/squba_palettes_standard.html","id":null,"dir":"Reference","previous_headings":"","what":"SQUBA Standard Color Palettes — squba_palettes_standard","title":"SQUBA Standard Color Palettes — squba_palettes_standard","text":"SQUBA Standard Color Palettes","code":""},{"path":"https://ssdqa.github.io/squba.gen/reference/squba_palettes_standard.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"SQUBA Standard Color Palettes — squba_palettes_standard","text":"","code":"squba_palettes_standard"},{"path":"https://ssdqa.github.io/squba.gen/reference/squba_palettes_standard.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"SQUBA Standard Color Palettes — squba_palettes_standard","text":"object class list length 6.","code":""},{"path":"https://ssdqa.github.io/squba.gen/news/index.html","id":"squbagen-development-version","dir":"Changelog","previous_headings":"","what":"squba.gen (development version)","title":"squba.gen (development version)","text":"Initial CRAN submission.","code":""}]
